<template>
  <div class="min-h-screen bg-gradient-to-br from-gray-50 to-gray-100">
    <!--ìˆ¨ê²¨ì§„ ìŒì„± ì¬ìƒ ì»¨í…Œì´ë„ˆ-->
    <div ref="audioContainer" style="display: none;"></div>
    <!-- ìë™ ì¢…ë£Œ ëª¨ë‹¬ (ì‹œìŠ¤í…œ íŠ¸ë¦¬ê±°) -->
    <AutoTerminationModal :show="showAutoTerminationModal" :ai-summary="aiSummary" v-model:memo="memo"
      @confirm="handleAutoTerminationConfirm" />

    <!-- ìˆ˜ë™ ì¢…ë£Œ í™•ì¸ ëª¨ë‹¬ -->
    <ManualEndCallModal :show="showManualEndModal" :ai-summary="aiSummary" v-model:memo="memo"
      @confirm="handleManualEndConfirm" />

    <!-- í†µí™” ì¢…ë£Œ í™•ì¸ ëª¨ë‹¬ -->
    <Teleport to="body">
      <div v-if="showEndConfirmModal" class="fixed inset-0 z-50 flex items-center justify-center">
        <div class="absolute inset-0 bg-black/50 backdrop-blur-sm" @click="handleEndConfirmCancel"></div>
        <div class="relative bg-white rounded-2xl shadow-2xl p-7 w-full max-w-sm mx-4">
          <h3 class="text-xl font-bold text-gray-900 mb-3">ìƒë‹´ ì¢…ë£Œ</h3>
          <p class="text-gray-600 mb-6">ì •ë§ ìƒë‹´ì„ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?</p>
          <div class="flex gap-3">
            <button @click="handleEndConfirmCancel"
              class="flex-1 px-4 py-3 border-2 border-gray-300 rounded-xl text-gray-700 font-semibold hover:bg-gray-50 transition-all">
              ì·¨ì†Œ
            </button>
            <button @click="handleEndConfirmOk"
              class="flex-1 px-4 py-3 bg-red-600 text-white rounded-xl font-semibold hover:bg-red-700 transition-all shadow-lg shadow-red-600/30">
              ì¢…ë£Œ
            </button>
          </div>
        </div>
      </div>
    </Teleport>

    <!-- ìƒë‹¨ í—¤ë” -->
    <header class="bg-white shadow-md border-b-2 border-primary-100">
      <div class="max-w-[1920px] mx-auto px-8 py-5">
        <div class="flex items-center justify-between">
          <div class="flex items-center gap-4">
            <div class="flex items-center gap-3">
              <div class="w-10 h-10 bg-primary-600 rounded-xl flex items-center justify-center shadow-lg">
                <svg class="w-6 h-6 text-white" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2L4 5v6.09c0 5.05 3.41 9.76 8 10.91 4.59-1.15 8-5.86 8-10.91V5l-8-3zm0 18.5c-3.76-1.08-6.5-5.06-6.5-9.41V6.3l6.5-2.6 6.5 2.6v4.79c0 4.35-2.74 8.33-6.5 9.41z"/>
                </svg>
              </div>
              <h1 class="text-2xl font-black text-gray-900 tracking-tight">Hear<span class="text-primary-600">O</span></h1>
            </div>
            <div class="h-8 w-px bg-gray-300"></div>
            <span class="text-sm font-semibold text-gray-600">ìƒë‹´ ì§„í–‰ ì¤‘</span>
          </div>

          <CallTimer :isActive="isCallActive" />

          <CounselorCallControls :isMuted="isMuted" @mute-changed="handleMuteChanged"
            @call-end-requested="handleManualEndRequest" />
        </div>
      </div>
    </header>

    <!-- ë©”ì¸ ì»¨í…ì¸  -->
    <main class="max-w-[1920px] mx-auto p-6">
      <GridLayout
        v-model:layout="layout"
        :col-num="12"
        :row-height="60"
        :is-draggable="false"
        :is-resizable="false"
        :vertical-compact="true"
        :margin="[24, 24]"
        :use-css-transforms="true"
        @layout-updated="saveLayout"
      >
        <!-- ê³ ê° ì •ë³´ íŒ¨ë„ -->
        <GridItem
          :x="layout[0].x"
          :y="layout[0].y"
          :w="layout[0].w"
          :h="layout[0].h"
          :i="layout[0].i"
          :min-w="2"
          :min-h="8"
          drag-allow-from=".drag-handle"
        >
          <div class="h-full overflow-hidden">
            <CustomerInfoSection />
          </div>
        </GridItem>

        <!-- STT ìë§‰ ì˜ì—­ -->
        <GridItem
          :x="layout[1].x"
          :y="layout[1].y"
          :w="layout[1].w"
          :h="layout[1].h"
          :i="layout[1].i"
          :min-w="4"
          :min-h="8"
          drag-allow-from=".drag-handle"
        >
          <div class="h-full overflow-hidden">
            <STTChatPanel
              :messages="sttMessages"
              :is-call-active="isCallActive"
              :counselor-name="counselorName"
              @toggle-profanity="handleToggleProfanity"
              @cancel-profanity="handleCancelProfanity"
              @counselor-message="handleCounselorMessage"
            />
          </div>
        </GridItem>

        <!-- AI ê°€ì´ë“œ íŒ¨ë„ -->
        <GridItem
          :x="layout[2].x"
          :y="layout[2].y"
          :w="layout[2].w"
          :h="layout[2].h"
          :i="layout[2].i"
          :min-w="2"
          :min-h="4"
          drag-allow-from=".drag-handle"
        >
          <div class="bg-white rounded-2xl shadow-lg border border-gray-200 h-full flex flex-col overflow-hidden">
            <div class="px-5 py-4 border-b border-gray-100 bg-gradient-to-r from-primary-50 to-blue-50">
              <h3 class="text-lg font-bold text-gray-900">AI ê°€ì´ë“œ</h3>
            </div>
            <div class="flex-1 overflow-y-auto p-5">
              <AIGuidePanel class="h-full" />
            </div>
          </div>
        </GridItem>

        <!-- ë©”ëª¨ íŒ¨ë„ -->
        <GridItem
          :x="layout[3].x"
          :y="layout[3].y"
          :w="layout[3].w"
          :h="layout[3].h"
          :i="layout[3].i"
          :min-w="2"
          :min-h="4"
          drag-allow-from=".drag-handle"
        >
          <div class="bg-white rounded-2xl shadow-lg border border-gray-200 h-full flex flex-col overflow-hidden">
            <div class="px-5 py-4 border-b border-gray-100 bg-gradient-to-r from-primary-50 to-blue-50">
              <h3 class="text-lg font-bold text-gray-900">ë©”ëª¨</h3>
            </div>
            <div class="flex-1 overflow-hidden p-5">
              <CallMemoPanel v-model="memo" :saved-label="memoSaveLabel" />
            </div>
          </div>
        </GridItem>
      </GridLayout>
    </main>
  </div>
</template>

<script setup>
import { ref, watch, computed, onBeforeUnmount, onMounted } from 'vue'
import { useRouter } from 'vue-router'
import { RoomEvent, Track } from 'livekit-client'
import { GridLayout, GridItem } from 'vue3-grid-layout-next'
import CallTimer from '@/components/counselor/CallTimer.vue'
import CustomerInfoSection from '@/components/counselor/CustomerInfoSection.vue'
import STTChatPanel from '@/components/counselor/STTChatPanel.vue'
import CounselorCallControls from '@/components/counselor/CounselorCallControls.vue'
import CallMemoPanel from '@/components/counselor/CallMemoPanel.vue'
import AIGuidePanel from '@/components/counselor/AIGuidePanel.vue'
import AutoTerminationModal from '@/components/call/AutoTerminationModal.vue'
import ManualEndCallModal from '@/components/call/ManualEndCallModal.vue'
import { startConsultation, getLatestConsultations } from '@/services/consultationService'
import { generateAISummary } from '@/services/aiService'
import { useNotificationStore } from '@/stores/notification'
import { useCallStore } from '@/stores/call'
import { useDashboardStore } from '@/stores/dashboard'
import { useAuthStore } from '@/stores/auth'
import axios from 'axios'
import { useAudioRecorder } from '@/composables/useAudioRecorder'

// ë¡œì»¬ AI ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ (Vite envë¡œ ë®ì–´ì“¸ ìˆ˜ ìˆìŒ) 
const TOXIC_API_URL = import.meta.env.VITE_TOXIC_API_URL || 'http://127.0.0.1:8000/unsmile'
// const WHISPER_API_URL = import.meta.env.VITE_WHISPER_API_URL || 'http://127.0.0.1:8000/stt'

// ìƒë‹´ì›: ê³ ê° ì˜¤ë””ì˜¤ ë”œë ˆì´(ê¸°ë³¸ 3ì´ˆ) 
const CUSTOMER_AUDIO_DELAY_SEC = 3
const MUTE_POSTPAD_MS = 600

// ìƒë‹´ì› Whisper STT: ë¬´ìŒ ê°ì§€(ë³´ìˆ˜ì ìœ¼ë¡œ ì§§ê²Œ) 
// const VAD_SILENCE_MS = Number(import.meta.env.VITE_COUNSELOR_VAD_SILENCE_MS || 650)
// const VAD_MIN_UTTER_MS = Number(import.meta.env.VITE_COUNSELOR_VAD_MIN_UTTER_MS || 800)

const router = useRouter()
const notificationStore = useNotificationStore()
const callStore = useCallStore()
const dashboardStore = useDashboardStore()
const authStore = useAuthStore()
const { startRecording, addTrack: addRecordingTrack, stopRecording, downloadRecording, cleanup: cleanupRecorder } = useAudioRecorder()

// --- ë ˆì´ì•„ì›ƒ ê´€ë¦¬ ---
const LAYOUT_STORAGE_KEY = 'counselor-call-layout'

// ê¸°ë³¸ ë ˆì´ì•„ì›ƒ ì„¤ì • (3ì—´ êµ¬ì¡°: ê³ ê°ì •ë³´ | ì‹¤ì‹œê°„ìë§‰ | AIê°€ì´ë“œ&ë©”ëª¨)
const defaultLayout = [
  { i: 'customer-info', x: 0, y: 0, w: 4, h: 10, minW: 2, minH: 6 },  // ì™¼ìª½ ì—´ (ì „ì²´ ë†’ì´)
  { i: 'stt-chat', x: 4, y: 0, w: 4, h: 10, minW: 4, minH: 8 },       // ì¤‘ì•™ ì—´ (ì „ì²´ ë†’ì´)
  { i: 'ai-guide', x: 8, y: 0, w: 4, h: 6, minW: 2, minH: 4 },        // ì˜¤ë¥¸ìª½ ì—´ ìƒë‹¨ (AI ê°€ì´ë“œ, í¬ê²Œ)
  { i: 'memo', x: 8, y: 8, w: 4, h: 4, minW: 2, minH: 3 }             // ì˜¤ë¥¸ìª½ ì—´ í•˜ë‹¨ (ë©”ëª¨, ì‘ê²Œ)
]

// ì €ì¥ëœ ë ˆì´ì•„ì›ƒ ë¡œë“œ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
const loadLayout = () => {
  try {
    const saved = localStorage.getItem(LAYOUT_STORAGE_KEY)
    if (saved) {
      return JSON.parse(saved)
    }
  } catch (error) {
    console.warn('[CounselorCallView] ë ˆì´ì•„ì›ƒ ë¡œë“œ ì‹¤íŒ¨:', error)
  }
  return JSON.parse(JSON.stringify(defaultLayout))
}

const layout = ref(loadLayout())

// ë ˆì´ì•„ì›ƒ ì €ì¥
const saveLayout = (newLayout) => {
  try {
    localStorage.setItem(LAYOUT_STORAGE_KEY, JSON.stringify(newLayout))
    console.log('[CounselorCallView] ë ˆì´ì•„ì›ƒ ì €ì¥ë¨')
  } catch (error) {
    console.warn('[CounselorCallView] ë ˆì´ì•„ì›ƒ ì €ì¥ ì‹¤íŒ¨:', error)
  }
}

// ë ˆì´ì•„ì›ƒ ì´ˆê¸°í™”
const resetLayout = () => {
  layout.value = JSON.parse(JSON.stringify(defaultLayout))
  localStorage.removeItem(LAYOUT_STORAGE_KEY)
  notificationStore.notifySuccess('ë ˆì´ì•„ì›ƒì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤')
  console.log('[CounselorCallView] ë ˆì´ì•„ì›ƒ ì´ˆê¸°í™”ë¨')
}


// ìƒë‹´ì› ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
const counselorName = computed(() => authStore.getUser?.name || 'ìƒë‹´ì›')

// ìŒì„± ë…¹ìŒ ì¢…ë£Œ ë° íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ê³µí†µ í—¬í¼ â€” ìˆ˜ë™Â·ìë™ì¢…ë£ŒÂ·ê³ ê°ì¢…ë£Œ ê³µìœ )
const stopAndSaveRecording = async () => {
  const recording = await stopRecording()
  if (recording) {
    const date = new Date().toISOString().slice(0, 10).replace(/-/g, '')
    downloadRecording(recording.blob, `ë…¹ìŒ_${date}_${Date.now()}`)
  }
}

// --- ìƒíƒœ ì •ì˜ ---
const isCallActive = ref(true)
const isMuted = ref(false)
let currentMicStream = null // getUserMedia stream ì°¸ì¡° â€” ì¢…ë£Œ ì‹œ íŠ¸ë™ ì •ë¦¬ìš©
const callStartTime = ref(null) // í†µí™” ì‹œì‘ ì‹œê°„ ì¶”ì 

// ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ìƒíƒœ
let audioCtx = null
const pipelines = new Map() // participantId -> { gain, delay, blocked, fallbackEl, analyser }
const audioContainer = ref(null)

// ìƒë‹´ì› Whisper VAD ìƒíƒœ
// let vadCtx = null
// let vadStream = null
// let vadSource = null
// let vadProcessor = null
// let vadBuffers = []
// let vadSpeeching = false
// let vadLastVoiceAt = 0
// let vadStartAt = 0

// ìë™ ì¢…ë£Œ ëª¨ë‹¬
const showAutoTerminationModal = ref(false)
const showManualEndModal = ref(false)
const showEndConfirmModal = ref(false) // ì¢…ë£Œ í™•ì¸ ëª¨ë‹¬

// í­ì–¸ 3íšŒ â†’ ìë™ ì¢…ë£Œ íŠ¸ë¦¬ê±° ê°ì§€
watch(() => callStore.autoTerminationTriggered, async (triggered) => {
  if (triggered) {
    // âš ï¸ ì¤‘ìš”: consultationIdë¥¼ ë¨¼ì € ì €ì¥
    const consultationId = callStore.currentConsultationId
    console.log('[CounselorCallView] ìë™ ì¢…ë£Œ - ì €ì¥ëœ consultationId:', consultationId)

    // ê³ ê°ì—ê²Œ ìë™ ì¢…ë£Œ ì‚¬ìœ  ì „ì†¡ í›„ LiveKit ì¢…ë£Œ
    if (callStore.livekitRoom) {
      try {
        // ê³ ê°ì—ê²Œ autoTermination ì‹ í˜¸ ì „ì†¡ (disconnect ì „)
        const payload = JSON.stringify({ type: 'autoTermination', reason: 'profanity' })
        const bytes = new TextEncoder().encode(payload)
        await callStore.livekitRoom.localParticipant.publishData(bytes, { reliable: true })
        console.log('[CounselorCallView] ìë™ ì¢…ë£Œ ì‹ í˜¸ ì „ì†¡ ì™„ë£Œ')

        // ë°ì´í„° ìˆ˜ì‹  ë³´ì¥ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
        await new Promise(resolve => setTimeout(resolve, 500))

        await stopLocalMicrophone()
        await callStore.livekitRoom.disconnect()
      } catch (e) {
        console.error('[CounselorCallView] ìë™ì¢…ë£Œ LiveKit ì¢…ë£Œ ì‹¤íŒ¨:', e)
      }
      callStore.setLivekitRoom(null)
    }

    // ëª¨ë‹¬ì„ ë¨¼ì € í‘œì‹œ (ë¡œë”© ìƒíƒœë¡œ)
    aiSummary.value = null // ë¡œë”© ìƒíƒœ
    showAutoTerminationModal.value = true
    console.log('[CounselorCallView] ìë™ ì¢…ë£Œ ëª¨ë‹¬ í‘œì‹œ (AI ìš”ì•½ ë¡œë”© ì¤‘)')

    // AI ìš”ì•½ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰, ëª¨ë‹¬ì€ ì´ë¯¸ í‘œì‹œë¨)
    try {
      console.log('[CounselorCallView] ìë™ ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ì‹œì‘')
      const fullTranscript = sttMessages.value
        .map(msg => `${msg.speaker}: ${msg.text}`)
        .join('\n')

      // ë””ë²„ê¹… ë¡œê·¸
      console.log('[CounselorCallView] ğŸ” ìë™ ì¢…ë£Œ AI ìš”ì•½ ìƒì„± ì²´í¬:')
      console.log('  - consultationId:', consultationId)
      console.log('  - sttMessages ê°œìˆ˜:', sttMessages.value.length)
      console.log('  - fullTranscript ê¸¸ì´:', fullTranscript.trim().length)

      if (consultationId && fullTranscript.trim()) {
        const summary = await generateAISummary(consultationId, fullTranscript)
        aiSummary.value = summary
        console.log('[CounselorCallView] ìë™ ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ì™„ë£Œ:', summary)
      } else {
        console.warn('[CounselorCallView] ìë™ ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ìŠ¤í‚µ (consultationId ë˜ëŠ” transcript ì—†ìŒ)')
        aiSummary.value = {
          title: 'ìš”ì•½ ìƒì„± ì‹¤íŒ¨',
          subtitle: 'ìƒë‹´ ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤',
          aiSummary: 'AI ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        }
      }
    } catch (aiError) {
      console.error('[CounselorCallView] ìë™ ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨:', aiError)
      aiSummary.value = {
        title: 'ìš”ì•½ ìƒì„± ì‹¤íŒ¨',
        subtitle: 'AI ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
        aiSummary: 'ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      }
    }
  }
})

const sttMessages = ref([])
const aiSummary = ref('')

// --- ë©”ëª¨ ë“œë˜í”„íŠ¸ ê´€ë¦¬ (ë³µêµ¬ëœ í•µì‹¬ ë¡œì§) ---
const memo = computed({
  get: () => callStore.callMemo,
  set: (val) => callStore.updateMemo(val)
})

const memoLastSavedAt = ref(null)
const memoDraftKey = ref('')
let memoSaveTimeout = null
let skipDraftSaveOnUnmount = false

const memoSaveLabel = computed(() => {
  if (!memoLastSavedAt.value) return memo.value?.trim().length ? 'ì„ì‹œ ì €ì¥ ì „' : '';
  const timeLabel = new Date(memoLastSavedAt.value).toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' });
  return `ì„ì‹œ ì €ì¥ë¨ Â· ${timeLabel}`;
})

const getSessionDraftKey = () => {
  if (typeof window === 'undefined') return '';
  let storedKey = localStorage.getItem('callMemoDraftKey');
  if (!storedKey) {
    storedKey = `callMemoDraft:${Date.now()}`;
    localStorage.setItem('callMemoDraftKey', storedKey);
  }
  return storedKey;
}

const resolveMemoDraftKey = (callId) => {
  return callId ? `callMemoDraft:${callId}` : getSessionDraftKey();
}

const loadMemoDraft = () => {
  if (!memoDraftKey.value) return;
  try {
    const raw = localStorage.getItem(memoDraftKey.value);
    if (!raw) return;
    const parsed = JSON.parse(raw);
    const draftText = typeof parsed === 'string' ? parsed : parsed?.memo;
    if (draftText && memo.value.trim().length === 0) {
      callStore.updateMemo(draftText);
    }
    if (parsed?.savedAt) memoLastSavedAt.value = parsed.savedAt;
  } catch (error) {
    console.warn('ë©”ëª¨ ë“œë˜í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨:', error);
  }
}

const saveMemoDraft = (value) => {
  if (!memoDraftKey.value) return;
  if (!value || value.trim().length === 0) {
    localStorage.removeItem(memoDraftKey.value);
    memoLastSavedAt.value = null;
    return;
  }
  const payload = { memo: value, savedAt: Date.now() };
  localStorage.setItem(memoDraftKey.value, JSON.stringify(payload));
  memoLastSavedAt.value = payload.savedAt;
}

const clearMemoDraft = (key = memoDraftKey.value) => {
  if (memoSaveTimeout) { clearTimeout(memoSaveTimeout); memoSaveTimeout = null; }
  if (key) localStorage.removeItem(key);
  memoLastSavedAt.value = null;
}

// ë©”ëª¨ ë³€ê²½ ê°ì‹œ (ìë™ ì €ì¥)
watch(memo, (newValue) => {
  if (memoSaveTimeout) clearTimeout(memoSaveTimeout);
  memoSaveTimeout = setTimeout(() => saveMemoDraft(newValue), 500);
})

// ì½œ ë³€ê²½ ì‹œ ë“œë˜í”„íŠ¸ í‚¤ ê°±ì‹ 
watch(() => callStore.currentCall?.id, (newId) => {
  const nextKey = resolveMemoDraftKey(newId);
  const previousKey = memoDraftKey.value;
  if (previousKey && previousKey !== nextKey) clearMemoDraft(previousKey);
  memoDraftKey.value = nextKey;
  skipDraftSaveOnUnmount = false;
  loadMemoDraft();
}, { immediate: true });

// ë©”ëª¨ ì„œë²„ ì €ì¥ (í†µí™” ì¢…ë£Œ ì‹œ /end APIë¡œ ì „ì†¡)
const saveMemoToServer = async (terminationReason = 'NORMAL') => {
  const memoValue = memo.value?.trim()
  const consultationId = callStore.currentCall?.consultationId ?? callStore.currentCall?.id

  if (!consultationId) {
    console.warn('[CounselorCallView] consultationIdê°€ ì—†ì–´ ë©”ëª¨ë¥¼ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤')
    return true
  }

  try {
    // STT ë©”ì‹œì§€ë¥¼ fullTranscriptë¡œ ë³€í™˜
    const fullTranscript = sttMessages.value
      .map(msg => `[${msg.speaker === 'agent' ? 'ìƒë‹´ì›' : 'ê³ ê°'}] ${msg.text}`)
      .join('\n') || 'ìƒë‹´ ë‚´ìš© ì—†ìŒ'

    // ì‹¤ì œ í†µí™” ì‹œê°„ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)
    const durationSeconds = callStartTime.value
      ? Math.floor((Date.now() - callStartTime.value) / 1000)
      : 0

    console.log('[CounselorCallView] í†µí™” ì‹œê°„:', durationSeconds, 'ì´ˆ (', Math.floor(durationSeconds / 60), 'ë¶„', durationSeconds % 60, 'ì´ˆ)')

    // í†µí™” ì¢…ë£Œ ì‹œ ë©”ëª¨ë¥¼ í¬í•¨í•˜ì—¬ finalizeConsultation API í˜¸ì¶œ
    // í­ì–¸ 3íšŒ ì´ìƒ ì‹œ PROFANITY_LIMITìœ¼ë¡œ ì„¤ì •
    const terminationReason = (callStore.currentCall.profanityCount >= 3) ? 'PROFANITY_LIMIT' : 'NORMAL'
    
    await axios.patch(`/api/v1/consultations/${consultationId}/end`, {
      userMemo: memoValue || '',
      fullTranscript: fullTranscript,
      profanityCount: callStore.currentCall.profanityCount || 0,
      avgAggressionScore: 0.0,
      maxAggressionScore: 0.0,
      terminationReason: terminationReason,
      durationSeconds: durationSeconds
    }, {
      headers: {
        Authorization: `Bearer ${localStorage.getItem('accessToken')}`
      }
    })

    console.log('âœ… [CounselorCallView] ë©”ëª¨ ì €ì¥ ì„±ê³µ')
    notificationStore.notifySuccess('ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤')
    return true
  } catch (error) {
    console.error('âŒ [CounselorCallView] ë©”ëª¨ ì €ì¥ ì‹¤íŒ¨:', error)
    notificationStore.notifyError('ë©”ëª¨ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤')
    return false
  }
}

// ë§ˆì´í¬ ì •ë¦¬: stored stream íŠ¸ë™ stop + LiveKit íŠ¸ë™ unpublish
const stopLocalMicrophone = async () => {
  if (currentMicStream) {
    currentMicStream.getTracks().forEach(track => track.stop())
    currentMicStream = null
  }

  if (callStore.livekitRoom) {
    try {
      const localParticipant = callStore.livekitRoom.localParticipant
      const audioPublication = localParticipant.getTrackPublication(Track.Source.Microphone)
      if (audioPublication?.track?.mediaStreamTrack) {
        audioPublication.track.mediaStreamTrack.stop()
      }
      if (audioPublication) {
        await localParticipant.unpublishTrack(audioPublication.track)
      }
    } catch (err) {
      console.error('[CounselorCallView] ë§ˆì´í¬ ì •ë¦¬ ì‹¤íŒ¨:', err)
    }
  }

  isMuted.value = true
}

// í†µí™” ì»¨íŠ¸ë¡¤ í•¸ë“¤ëŸ¬
// ìŒì†Œê±° í† ê¸€ í•¸ë“¤ëŸ¬
const handleMuteChanged = async (muted) => {
  console.log(`[CounselorCallView] handleMuteChanged í˜¸ì¶œ: muted=${muted}`)

  if (!callStore.livekitRoom) {
    console.warn('[CounselorCallView] LiveKit roomì´ ì—†ìŠµë‹ˆë‹¤')
    return
  }

  try {
    const localParticipant = callStore.livekitRoom.localParticipant

    // ë¡œì»¬ ì°¸ê°€ìì˜ ì˜¤ë””ì˜¤ íŠ¸ë™ ì°¾ê¸°
    const audioPublication = localParticipant.getTrackPublication(Track.Source.Microphone)
    console.log(`[CounselorCallView] ì˜¤ë””ì˜¤ íŠ¸ë™ ì¡°íšŒ ê²°ê³¼: ${audioPublication ? 'ìˆìŒ' : 'ì—†ìŒ'}`)

    if (audioPublication && audioPublication.track) {
      // ê¸°ì¡´ íŠ¸ë™ì´ ìˆìœ¼ë©´ mute/unmute
      if (muted) {
        await audioPublication.mute()
      } else {
        await audioPublication.unmute()
      }

      isMuted.value = muted
      console.log(`[CounselorCallView] ë§ˆì´í¬ ${muted ? 'ìŒì†Œê±°' : 'ìŒì†Œê±° í•´ì œ'}`)
    } else {
      // íŠ¸ë™ì´ ì—†ìœ¼ë©´ ë§ˆì´í¬ í™œì„±í™” ë¨¼ì € ì‹œë„
      console.log('[CounselorCallView] ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ì–´ì„œ ë§ˆì´í¬ í™œì„±í™” ì‹œë„')

      try {
        // ê¸°ì¡´ stream ì •ë¦¬ í›„ ìƒˆë¡œìš´ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
        if (currentMicStream) {
          currentMicStream.getTracks().forEach(t => t.stop())
        }
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
        currentMicStream = stream
        const audioTracks = stream.getAudioTracks()

        if (audioTracks.length > 0) {
          // publishTrackì˜ ë°˜í™˜ê°’(LocalTrackPublication)ì„ ì§ì ‘ ì‚¬ìš©
          const publication = await localParticipant.publishTrack(audioTracks[0])
          console.log('[CounselorCallView] ë§ˆì´í¬ í™œì„±í™” ì„±ê³µ')

          // í™œì„±í™” í›„ ì¦‰ì‹œ mute ì²˜ë¦¬ (ìŒì†Œê±° ë²„íŠ¼ì„ ëˆŒë €ìœ¼ë¯€ë¡œ)
          if (muted) {
            await publication.mute()
            console.log('[CounselorCallView] ë§ˆì´í¬ í™œì„±í™” í›„ ì¦‰ì‹œ ìŒì†Œê±° ì²˜ë¦¬ ì™„ë£Œ')
          } else {
            console.log('[CounselorCallView] ë§ˆì´í¬ í™œì„±í™” ì™„ë£Œ (ìŒì†Œê±° í•´ì œ ìƒíƒœ)')
          }

          isMuted.value = muted
        }
      } catch (micError) {
        console.error('[CounselorCallView] ë§ˆì´í¬ í™œì„±í™” ì‹¤íŒ¨:', micError)
        notificationStore.notifyError('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”')
        // ìƒíƒœ ë³µì›í•˜ì§€ ì•ŠìŒ (ë§ˆì´í¬ê°€ ì—†ëŠ” ìƒíƒœ ìœ ì§€)
      }
    }
  } catch (error) {
    console.error('[CounselorCallView] ë§ˆì´í¬ ì œì–´ ì‹¤íŒ¨:', error)
    // ì—ëŸ¬ ë°œìƒ ì‹œ ìƒíƒœ ë³µì›
    isMuted.value = !muted
  }
}

// Manual end modal request - í™•ì¸ ëª¨ë‹¬ í‘œì‹œ
const handleManualEndRequest = () => {
  console.log('[CounselorCallView] í†µí™” ì¢…ë£Œ ë²„íŠ¼ í´ë¦­ - í™•ì¸ ëª¨ë‹¬ í‘œì‹œ')
  showEndConfirmModal.value = true
}

// ì¢…ë£Œ í™•ì¸ ëª¨ë‹¬ - ì·¨ì†Œ
const handleEndConfirmCancel = () => {
  showEndConfirmModal.value = false
}

// ì¢…ë£Œ í™•ì¸ ëª¨ë‹¬ - í™•ì¸ (ì‹¤ì œ ì¢…ë£Œ ì²˜ë¦¬)
const handleEndConfirmOk = async () => {
  showEndConfirmModal.value = false
  console.log('[CounselorCallView] í†µí™” ì¢…ë£Œ í™•ì¸')

  try {
    // âš ï¸ ì¤‘ìš”: consultationIdë¥¼ ë¨¼ì € ì €ì¥ (endCall()ì´ ì´ˆê¸°í™”í•˜ê¸° ì „ì—)
    const consultationId = callStore.currentConsultationId
    console.log('[CounselorCallView] ì €ì¥ëœ consultationId:', consultationId)

    // í†µí™” ì¢…ë£Œ ë²„íŠ¼ì„ ëˆ„ë¥´ëŠ” ì¦‰ì‹œ LiveKit ì—°ê²° ì¢…ë£Œ (ê³ ê°ì—ê²Œ ì¦‰ì‹œ ì•Œë¦¼)
    isCallActive.value = false
    callStore.endCall()

    // ìŒì„± ë…¹ìŒ ì¢…ë£Œ ë° íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    await stopAndSaveRecording()

    if (callStore.livekitRoom) {
      console.log('[CounselorCallView] LiveKit ì—°ê²° ì¦‰ì‹œ ì¢…ë£Œ (í†µí™” ì¢…ë£Œ ë²„íŠ¼)')

      try {
        // 1. ë§ˆì´í¬ ì •ë¦¬ (stream ë° LiveKit íŠ¸ë™)
        await stopLocalMicrophone()
        console.log('[CounselorCallView] ë§ˆì´í¬ ì •ë¦¬ ì™„ë£Œ')

        // 2. LiveKit ë£¸ ì—°ê²° ì¢…ë£Œ
        await callStore.livekitRoom.disconnect()
        console.log('[CounselorCallView] LiveKit ì—°ê²° ì¢…ë£Œ ì™„ë£Œ')
      } catch (disconnectError) {
        console.error('[CounselorCallView] LiveKit ì—°ê²° ì¢…ë£Œ ì‹¤íŒ¨:', disconnectError)
      }

      callStore.setLivekitRoom(null)
    }

    // ë§ˆì´í¬ ìƒíƒœë¥¼ ìŒì†Œê±°ë¡œ ì„¤ì • (UI ë™ê¸°í™”)
    isMuted.value = true

    // ëª¨ë‹¬ì„ ë¨¼ì € í‘œì‹œ (ë¡œë”© ìƒíƒœë¡œ)
    aiSummary.value = null // ë¡œë”© ìƒíƒœ
    showManualEndModal.value = true
    console.log('[CounselorCallView] ìˆ˜ë™ ì¢…ë£Œ ëª¨ë‹¬ í‘œì‹œ (AI ìš”ì•½ ë¡œë”© ì¤‘)')

    // AI ìš”ì•½ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰, ëª¨ë‹¬ì€ ì´ë¯¸ í‘œì‹œë¨)
    try {
      console.log('[CounselorCallView] AI ìš”ì•½ ìƒì„± ì‹œì‘')
      const fullTranscript = sttMessages.value
        .map(msg => `${msg.speaker}: ${msg.text}`)
        .join('\n')

      // ë””ë²„ê¹… ë¡œê·¸
      console.log('[CounselorCallView] ğŸ” AI ìš”ì•½ ìƒì„± ì²´í¬:')
      console.log('  - consultationId:', consultationId)
      console.log('  - sttMessages ê°œìˆ˜:', sttMessages.value.length)
      console.log('  - fullTranscript ê¸¸ì´:', fullTranscript.trim().length)
      console.log('  - fullTranscript ë‚´ìš©:', fullTranscript.substring(0, 200))

      if (consultationId && fullTranscript.trim()) {
        const summary = await generateAISummary(consultationId, fullTranscript)
        aiSummary.value = summary // { title, subtitle, aiSummary }
        console.log('[CounselorCallView] AI ìš”ì•½ ìƒì„± ì™„ë£Œ:', summary)
      } else {
        console.warn('[CounselorCallView] AI ìš”ì•½ ìƒì„± ìŠ¤í‚µ (consultationId ë˜ëŠ” transcript ì—†ìŒ)')
        aiSummary.value = {
          title: 'ìš”ì•½ ìƒì„± ì‹¤íŒ¨',
          subtitle: 'ìƒë‹´ ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤',
          aiSummary: 'AI ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
        }
      }
    } catch (aiError) {
      console.error('[CounselorCallView] AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨:', aiError)
      aiSummary.value = {
        title: 'ìš”ì•½ ìƒì„± ì‹¤íŒ¨',
        subtitle: 'AI ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
        aiSummary: 'ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
      }
    }
  } catch (error) {
    console.error('[CounselorCallView] í†µí™” ì¢…ë£Œ ë²„íŠ¼ ì²˜ë¦¬ ì‹¤íŒ¨:', error)
    notificationStore.notifyError('í†µí™” ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤')
  }
}

// Manual end modal confirm
const handleManualEndConfirm = async () => {
  console.log('[CounselorCallView] ìˆ˜ë™ ì¢…ë£Œ ëª¨ë‹¬ í™•ì¸ ë²„íŠ¼ í´ë¦­')

  try {
    showManualEndModal.value = false

    // ë©”ëª¨ ì €ì¥
    const saved = await saveMemoToServer()
    if (saved) {
      clearMemoDraft()
      skipDraftSaveOnUnmount = true
    }

    // ìƒë‹´ì‚¬ ìƒíƒœë¥¼ RESTë¡œ (ëŒ€ì‹œë³´ë“œì—ì„œ ìˆ˜ë™ ON ëŒ€ê¸°)
    try {
      await axios.patch('/api/v1/users/me/status', { status: 'REST' })
      dashboardStore.consultationStatus.isActive = false
      console.log('[CounselorCallView] ìƒë‹´ì‚¬ ìƒíƒœ REST, ìƒë‹´ OFF')
    } catch (statusError) {
      console.error('[CounselorCallView] ìƒíƒœ ë³µêµ¬ ì‹¤íŒ¨:', statusError)
    }

    // call store ë¦¬ì…‹ ë° ëŒ€ì‹œë³´ë“œ ì´ë™
    callStore.resetCall()
    console.log('[CounselorCallView] í†µí™” ì¢…ë£Œ ì™„ë£Œ, ëŒ€ì‹œë³´ë“œë¡œ ì´ë™')
    router.push({ name: 'dashboard' })
  } catch (error) {
    console.error('[CounselorCallView] ìˆ˜ë™ ì¢…ë£Œ í™•ì¸ ì²˜ë¦¬ ì‹¤íŒ¨:', error)
    notificationStore.notifyError('í†µí™” ì¢…ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤')
    // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ëŒ€ì‹œë³´ë“œë¡œ ì´ë™
    router.push({ name: 'dashboard' })
  }
}


// ìë™ ì¢…ë£Œ ëª¨ë‹¬ í™•ì¸ í•¸ë“¤ëŸ¬
const handleAutoTerminationConfirm = async () => {
  showAutoTerminationModal.value = false

  try {
    // í†µí™” ì¢…ë£Œ ì²˜ë¦¬
    const callData = callStore.endCall()

    // ë©”ëª¨ ì €ì¥
    const saved = await saveMemoToServer()
    if (saved) {
      clearMemoDraft()
      skipDraftSaveOnUnmount = true
    }

    // ìŒì„± ë…¹ìŒ ì¢…ë£Œ ë° íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    await stopAndSaveRecording()

    // ìƒë‹´ì‚¬ ìƒíƒœë¥¼ RESTë¡œ (ëŒ€ì‹œë³´ë“œì—ì„œ ìˆ˜ë™ ON ëŒ€ê¸°)
    try {
      await axios.patch('/api/v1/users/me/status', { status: 'REST' })
      dashboardStore.consultationStatus.isActive = false
      console.log('[CounselorCallView] ìƒë‹´ì‚¬ ìƒíƒœ REST, ìƒë‹´ OFF (ìë™ ì¢…ë£Œ)')
    } catch (statusError) {
      console.error('[CounselorCallView] ìƒíƒœ ë³µêµ¬ ì‹¤íŒ¨:', statusError)
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    callStore.resetCall()

    // ëŒ€ì‹œë³´ë“œë¡œ ì´ë™í•˜ë©´ì„œ TimeModal íŠ¸ë¦¬ê±° í”Œë˜ê·¸ ì„¤ì •
    localStorage.setItem('triggerTimeModal', 'true')
    router.push({ name: 'dashboard' })

    notificationStore.notifyInfo('ê³ ê°ì´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤. 10ë¶„ê°„ ì˜ë¬´ íœ´ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤.')
  } catch (error) {
    console.error('ìë™ ì¢…ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨:', error)
    notificationStore.notifyError('í†µí™” ì¢…ë£Œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤')
    router.push({ name: 'dashboard' })
  }
}

// ìš•ì„¤ í‘œì‹œ/ìˆ¨ê¸°ê¸° í† ê¸€
const handleToggleProfanity = (index) => {
  sttMessages.value[index].showOriginal = !sttMessages.value[index].showOriginal
}

// ìš•ì„¤ ê°ì§€ ì·¨ì†Œ
const handleCancelProfanity = (index) => {
  const message = sttMessages.value[index]

  // ì´ë¯¸ ì·¨ì†Œëœ ê²½ìš° ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
  if (message.isProfanityCancelled) {
    return
  }

  // ì·¨ì†Œ í”Œë˜ê·¸ ì„¤ì •
  message.isProfanityCancelled = true

  // í­ì–¸ ì¹´ìš´íŠ¸ ê°ì†Œ
  callStore.decrementProfanityCount()

  console.log('[CounselorCall] í­ì–¸ ê°ì§€ ì·¨ì†Œë¨. í˜„ì¬ ì¹´ìš´íŠ¸:', callStore.currentCall.profanityCount)

  // ì·¨ì†Œ ì•Œë¦¼ í‘œì‹œ
  notificationStore.notifyInfo('í­ì–¸ ê°ì§€ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤')
}

// ìƒë‹´ì‚¬ ë©”ì‹œì§€ ì…ë ¥ í•¸ë“¤ëŸ¬
const handleCounselorMessage = (message) => {
  addSttMessage({
    speaker: 'agent',
    text: message,
    maskedText: '',
    hasProfanity: false,
    confidence: 1.0
  })
}

/**
 * STT ë©”ì‹œì§€ ì¶”ê°€ (ì‹¤ì œ STT/WebSocket ì—°ë™ ì‹œ ì´ í•¨ìˆ˜ í˜¸ì¶œ)
 * @param {Object} message - STT ë©”ì‹œì§€ ê°ì²´
 * @param {string} message.speaker - í™”ì ('agent' | 'customer')
 * @param {string} message.text - ì›ë³¸ í…ìŠ¤íŠ¸
 * @param {string} message.maskedText - ë§ˆìŠ¤í‚¹ëœ í…ìŠ¤íŠ¸
 * @param {boolean} message.hasProfanity - í­ì–¸ í¬í•¨ ì—¬ë¶€
 * @param {number} message.confidence - ì‹ ë¢°ë„
 */
const addSttMessage = (message) => {
  const timestamp = new Date().toLocaleTimeString('ko-KR', {
    hour: '2-digit',
    minute: '2-digit'
  })

  sttMessages.value.push({
    ...message,
    timestamp,
    showOriginal: false,
    isProfanityCancelled: false
  })

  // ë§ˆìŠ¤í‚¹(í­ì–¸) ê°ì§€ ì‹œ ì•Œë¦¼ í‘œì‹œ ë° ì¹´ìš´íŠ¸ ì¦ê°€
  if (message.hasProfanity) {
    // callStoreì—ì„œ í­ì–¸ ì¹´ìš´íŠ¸ ì¦ê°€ (3íšŒ ë„ë‹¬ ì‹œ ìë™ ì¢…ë£Œ íŠ¸ë¦¬ê±°)
    const newCount = callStore.incrementProfanityCount()

    // ì•Œë¦¼ í‘œì‹œ
    notificationStore.notifyProfanity(newCount)

    console.log(`[CounselorCall] í­ì–¸ ê°ì§€ (${newCount}/3íšŒ)`)
  }
}

// ---- ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ í—¬í¼ ----
const ensureAudioContext = async () => {
  if (!audioCtx) {
    audioCtx = new (window.AudioContext || window.webkitAudioContext)()
  }
  if (audioCtx.state === 'suspended') {
    try { await audioCtx.resume() } catch { }
  }
  return audioCtx
}

const attachDelayedCustomerAudio = async (track, participantId) => {
  if (!track?.mediaStreamTrack) return

  const ctx = await ensureAudioContext()
  if (pipelines.has(participantId)) return

  // 1. ì¦‰ì‹œ ì¬ìƒìš© Fallback ì˜¤ë””ì˜¤ ìƒì„± (ì§€ì—° ì—†ìŒ)
  // Web Audioê°€ í™œì„±í™”ë˜ê¸° ì „ì—ë„ ì†Œë¦¬ê°€ ë‚˜ê²Œ í•˜ì—¬ ëŠê¹€ì„ ë°©ì§€í•©ë‹ˆë‹¤.
  const fallbackEl = track.attach()
  audioContainer.value?.appendChild(fallbackEl)

  // 2. Web Audio íŒŒì´í”„ë¼ì¸ êµ¬ì„±
  const stream = new MediaStream([track.mediaStreamTrack])
  const source = ctx.createMediaStreamSource(stream)

  const delayNode = ctx.createDelay(10)
  delayNode.delayTime.value = CUSTOMER_AUDIO_DELAY_SEC

  const gainNode = ctx.createGain()
  gainNode.gain.value = 1

  // 3. ì‹ í˜¸ ê°ì§€ìš© Analyser ì¶”ê°€ (TestRTCì˜ í•µì‹¬)
  const analyser = ctx.createAnalyser()
  analyser.fftSize = 256
  const pcmData = new Float32Array(analyser.fftSize)

  // ì—°ê²°: Source -> Delay -> Gain -> Destination & Analyser
  source.connect(delayNode)
  delayNode.connect(gainNode)
  gainNode.connect(ctx.destination)
  gainNode.connect(analyser)

  pipelines.set(participantId, {
    gain: gainNode,
    delay: delayNode,
    blocked: false,
    fallbackEl,
    analyser
  })

  // 4. ì§€ì—°ëœ ì†Œë¦¬ê°€ ë‚˜ì˜¤ê¸° ì‹œì‘í•˜ëŠ”ì§€ ê°ì‹œ ë£¨í”„
  const checkSignal = () => {
    const pipe = pipelines.get(participantId)
    if (!pipe) return

    analyser.getFloatTimeDomainData(pcmData)
    let sumSquares = 0
    for (const amplitude of pcmData) {
      sumSquares += amplitude * amplitude
    }
    const rms = Math.sqrt(sumSquares / pcmData.length)

    // ì§€ì—°ëœ ì†Œë¦¬(RMS)ê°€ ì¼ì • í¬ê¸° ì´ìƒ ê°ì§€ë˜ë©´ ì›ë³¸ ì†Œë¦¬ë¥¼ ë”
    if (rms > 0.01) {
      console.log(`[Audio] ${participantId} ì§€ì—° ì‹ í˜¸ ê°ì§€ -> ì›ë³¸ ìŒì†Œê±°`)
      pipe.fallbackEl.muted = true
    } else {
      // ì‹ í˜¸ê°€ ì˜¬ ë•Œê¹Œì§€ ê³„ì† í™•ì¸
      requestAnimationFrame(checkSignal)
    }
  }

  checkSignal()
}

const setCustomerAudioMuted = (participantId, muted) => {
  const p = pipelines.get(participantId)
  if (!p) return
  const target = muted ? 0 : 1
  try {
    p.gain.gain.setTargetAtTime(target, audioCtx.currentTime, 0.02)
  } catch {
    p.gain.gain.value = target
  }
}

const blockCustomerAudioUntilNextStt = (participantId) => {
  const p = pipelines.get(participantId)
  if (!p) return
  p.blocked = true
  setCustomerAudioMuted(participantId, true)
}

const scheduleUnblockOnNextStt = (participantId) => {
  const p = pipelines.get(participantId)
  if (!p) return
  if (!p.blocked) return

  // ë‹¤ìŒ STTê°€ ì™”ì„ ë•Œ, "ê·¸ ë‹¤ìŒ êµ¬ê°„"ë¶€í„° ë‹¤ì‹œ ë“¤ë¦¬ê²Œ í•˜ëŠ” ë³´ìˆ˜ì  ë°©ì‹
  // (ë”œë ˆì´ ë§Œí¼ ê¸°ë‹¤ë ë‹¤ê°€ í•´ì œ)
  setTimeout(() => {
    // ì•„ì§ë„ blocked ìƒíƒœë©´ í•´ì œ
    const latest = pipelines.get(participantId)
    if (!latest) return
    latest.blocked = false
    setCustomerAudioMuted(participantId, false)
  }, CUSTOMER_AUDIO_DELAY_SEC * 1000 + MUTE_POSTPAD_MS)
}

// ---- LiveKit DataReceived payload íŒŒì‹± ----
const safeParsePayload = (payload) => {
  try {
    const text = new TextDecoder().decode(payload)
    return JSON.parse(text)
  } catch {
    return null
  }
}

// ---- unsmile í­ë ¥ì„± ê²€ì‚¬ ----
const analyzeToxicity = async (text) => {
  if (!text?.trim()) return { toxic: false, score: 0 }
  try {
    const res = await fetch(TOXIC_API_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text })
    })
    if (!res.ok) throw new Error(`HTTP ${res.status}`)
    const data = await res.json()
    return {
      toxic: !!data.toxic,
      score: typeof data.score === 'number' ? data.score : (typeof data.prob === 'number' ? data.prob : 0)
    }
  } catch (e) {
    console.warn('[CounselorCallView] í­ë ¥ì„± ê²€ì‚¬ ì‹¤íŒ¨(ìš°íšŒ):', e)
    return { toxic: false, score: 0 }
  }
}

// ---- í…ìŠ¤íŠ¸ ë§ˆìŠ¤í‚¹ ----
const maskText = (text) => {
  if (!text) return ''
  // ë„ˆë¬´ ê³µê²©ì ìœ¼ë¡œ ì§€ìš°ê¸°ë³´ë‹¨, ê¸€ì ì¼ë¶€ë§Œ ë¸”ëŸ¬ í‘œì‹œ
  return text.replace(/[\S]/g, 'â€¢')
}

// ---- Whisper STT (ìƒë‹´ì› ë¡œì»¬) ----
// const floatTo16BitPCM = (float32) => {
//   const out = new Int16Array(float32.length)
//   for (let i = 0; i < float32.length; i++) {
//     let s = Math.max(-1, Math.min(1, float32[i]))
//     out[i] = s < 0 ? s * 0x8000 : s * 0x7fff
//   }
//   return out
// }

// const encodeWav16kMono = async (float32, inputSampleRate) => {
//   // ê°„ë‹¨í•œ linear resample â†’ 16k
//   const targetRate = 16000
//   const ratio = inputSampleRate / targetRate
//   const targetLength = Math.floor(float32.length / ratio)
//   const resampled = new Float32Array(targetLength)
//   for (let i = 0; i < targetLength; i++) {
//     const idx = i * ratio
//     const i0 = Math.floor(idx)
//     const i1 = Math.min(float32.length - 1, i0 + 1)
//     const t = idx - i0
//     resampled[i] = float32[i0] * (1 - t) + float32[i1] * t
//   }

//   const pcm16 = floatTo16BitPCM(resampled)
//   const headerSize = 44
//   const buffer = new ArrayBuffer(headerSize + pcm16.byteLength)
//   const view = new DataView(buffer)
//   const writeString = (offset, str) => {
//     for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i))
//   }

//   writeString(0, 'RIFF')
//   view.setUint32(4, 36 + pcm16.byteLength, true)
//   writeString(8, 'WAVE')
//   writeString(12, 'fmt ')
//   view.setUint32(16, 16, true) // PCM
//   view.setUint16(20, 1, true) // PCM
//   view.setUint16(22, 1, true) // mono
//   view.setUint32(24, targetRate, true)
//   view.setUint32(28, targetRate * 2, true) // byte rate
//   view.setUint16(32, 2, true) // block align
//   view.setUint16(34, 16, true) // bits
//   writeString(36, 'data')
//   view.setUint32(40, pcm16.byteLength, true)
//   new Uint8Array(buffer, headerSize).set(new Uint8Array(pcm16.buffer))
//   return new Blob([buffer], { type: 'audio/wav' })
// }

// const sendToWhisper = async (wavBlob) => {
//   try {
//     const form = new FormData()
//     form.append('file', wavBlob, 'audio.wav')
//     const res = await fetch(WHISPER_API_URL, {
//       method: 'POST',
//       body: form
//     })
//     if (!res.ok) throw new Error(`HTTP ${res.status}`)
//     const data = await res.json().catch(() => null)

//     // ì„œë²„ê°€ {text:"..."} ë˜ëŠ” {transcript:"..."} ë“±ì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
//     const text = data?.text ?? data?.transcript ?? data?.result ?? ''
//     return String(text || '').trim()
//   } catch (e) {
//     console.warn('[CounselorCallView] Whisper STT ì‹¤íŒ¨:', e)
//     return ''
//   }
// }

// const startCounselorWhisperVad = async () => {
//   try {
//     if (vadCtx) return
//     vadCtx = new (window.AudioContext || window.webkitAudioContext)()
//     vadStream = await navigator.mediaDevices.getUserMedia({ audio: true })
//     vadSource = vadCtx.createMediaStreamSource(vadStream)
//     // ScriptProcessorëŠ” deprecatedì§€ë§Œ í˜¸í™˜ì„± ì¢‹ìŒ
//     vadProcessor = vadCtx.createScriptProcessor(2048, 1, 1)

//     vadProcessor.onaudioprocess = async (e) => {
//       const input = e.inputBuffer.getChannelData(0)

//       // RMS ê³„ì‚°
//       let sum = 0
//       for (let i = 0; i < input.length; i++) sum += input[i] * input[i]
//       const rms = Math.sqrt(sum / input.length)
//       const now = performance.now()

//       const isVoice = rms > 0.02
//       if (isVoice) {
//         if (!vadSpeeching) {
//           vadSpeeching = true
//           vadStartAt = now
//           vadBuffers = []
//         }
//         vadLastVoiceAt = now
//         vadBuffers.push(new Float32Array(input))
//       } else if (vadSpeeching) {
//         // ë§í•˜ë˜ ì¤‘ ë¬´ìŒì´ VAD_SILENCE_MS ì´ìƒì´ë©´ í•œ êµ¬ê°„ ì¢…ë£Œ
//         if (now - vadLastVoiceAt >= VAD_SILENCE_MS) {
//           const dur = now - vadStartAt
//           vadSpeeching = false

//           if (dur >= VAD_MIN_UTTER_MS && vadBuffers.length) {
//             const total = vadBuffers.reduce((acc, a) => acc + a.length, 0)
//             const merged = new Float32Array(total)
//             let off = 0
//             for (const b of vadBuffers) {
//               merged.set(b, off)
//               off += b.length
//             }
//             vadBuffers = []

//             const wav = await encodeWav16kMono(merged, vadCtx.sampleRate)
//             const text = await sendToWhisper(wav)
//             if (text) {
//               addSttMessage({
//                 speaker: 'agent',
//                 text,
//                 maskedText: '',
//                 hasProfanity: false,
//                 confidence: 0.9
//               })
//             }
//           } else {
//             vadBuffers = []
//           }
//         }
//       }
//     }

//     vadSource.connect(vadProcessor)
//     vadProcessor.connect(vadCtx.destination) // ì²˜ë¦¬ êµ¬ë™ìš©(ì¶œë ¥ ìŒëŸ‰ì€ ê±°ì˜ ë¬´ì‹œë¨)
//     console.log('[CounselorCallView] ìƒë‹´ì› Whisper VAD ì‹œì‘')
//   } catch (e) {
//     console.warn('[CounselorCallView] Whisper VAD ì‹œì‘ ì‹¤íŒ¨:', e)
//   }
// }

// const stopCounselorWhisperVad = async () => {
//   try {
//     vadProcessor?.disconnect?.()
//     vadSource?.disconnect?.()
//     vadStream?.getTracks?.().forEach(t => t.stop())
//     await vadCtx?.close?.()
//   } catch {
//     // ignore
//   } finally {
//     vadCtx = null
//     vadStream = null
//     vadSource = null
//     vadProcessor = null
//     vadBuffers = []
//     vadSpeeching = false
//   }
// }

onBeforeUnmount(() => {
  if (memoSaveTimeout) clearTimeout(memoSaveTimeout);
  if (!skipDraftSaveOnUnmount && memo.value?.trim().length) saveMemoDraft(memo.value);
})

defineExpose({ addSttMessage })

onMounted(async () => {
  // ë ˆì´ì•„ì›ƒ ì´ˆê¸°í™” (ìƒˆë¡œìš´ 3ì—´ êµ¬ì¡° ì ìš©)
  console.log('[CounselorCallView] ë ˆì´ì•„ì›ƒ ì´ˆê¸°í™” ì¤‘...')
  layout.value = JSON.parse(JSON.stringify(defaultLayout))
  localStorage.removeItem(LAYOUT_STORAGE_KEY)
  
  // í†µí™” ì‹œì‘ ì‹œê°„ ê¸°ë¡
  callStartTime.value = Date.now()
  console.log('[CounselorCallView] í†µí™” ì‹œì‘ ì‹œê°„ ê¸°ë¡:', new Date(callStartTime.value).toLocaleTimeString())

  // call storeì— ì €ì¥ëœ LiveKit room í™•ì¸
  if (callStore.livekitRoom) {
    console.log('[CounselorCallView] ê¸°ì¡´ LiveKit ì—°ê²° ì‚¬ìš©:', callStore.livekitRoom.name)

    const room = callStore.livekitRoom

    // === ìƒë‹´ ì‹œì‘ API í˜¸ì¶œ ë° consultationId ê³ ê°ì—ê²Œ ì „ì†¡ ===
    try {
      const matchedData = dashboardStore.matchedData
      if (matchedData?.customerId && matchedData?.registrationId) {
        console.log('[CounselorCallView] ìƒë‹´ ì‹œì‘ API í˜¸ì¶œ...', { customerId: matchedData.customerId, registrationId: matchedData.registrationId })

        const response = await axios.post('/api/v1/consultations', {
          customerId: matchedData.customerId,
          registrationId: matchedData.registrationId
        })

        const consultationId = response.data?.data?.consultationId
        if (consultationId) {
          // callStoreì— ì €ì¥
          callStore.setConsultationId(consultationId)
          console.log('[CounselorCallView] consultationId íšë“:', consultationId)

          // ê³ ê°ì´ í†µí™” í™”ë©´ ì§„ì… ë° ë¦¬ìŠ¤ë„ˆ ë“±ë¡í•  ì‹œê°„ í™•ë³´ í›„ ì „ì†¡
          // 500ms í›„ ì²« ì „ì†¡, ì´í›„ 2ì´ˆë§ˆë‹¤ 3ë²ˆ ì¬ì „ì†¡ (ì´ 4ë²ˆ)
          const sendConsultationId = async () => {
            try {
              const payload = {
                type: 'consultationId',
                consultationId: consultationId,
                ts: Date.now()
              }
              const bytes = new TextEncoder().encode(JSON.stringify(payload))
              await room.localParticipant.publishData(bytes, { reliable: true })
              console.log('[CounselorCallView] consultationId ê³ ê°ì—ê²Œ ì „ì†¡ ì™„ë£Œ')
            } catch (sendErr) {
              console.error('[CounselorCallView] consultationId ì „ì†¡ ì‹¤íŒ¨:', sendErr)
            }
          }

          // 500ms í›„ ì²« ì „ì†¡
          setTimeout(sendConsultationId, 500)
          // 2ì´ˆ, 4ì´ˆ, 6ì´ˆ í›„ ì¬ì „ì†¡ (ê³ ê°ì´ ëŠ¦ê²Œ ì…ì¥í•  ê²½ìš° ëŒ€ë¹„)
          setTimeout(sendConsultationId, 2000)
          setTimeout(sendConsultationId, 4000)
          setTimeout(sendConsultationId, 6000)
        }
      } else {
        console.warn('[CounselorCallView] matchedDataì— customerId ë˜ëŠ” registrationId ì—†ìŒ:', matchedData)
      }
    } catch (err) {
      console.error('[CounselorCallView] ìƒë‹´ ì‹œì‘ API í˜¸ì¶œ ì‹¤íŒ¨:', err)
    }

    if (room.remoteParticipants.size > 0) {
      console.log('[CounselorCallView] ê³ ê° ì´ë¯¸ ë°©ì— ìˆìŒ')
    } else {
      console.log('[CounselorCallView] ê³ ê° ì•„ì§ ë¯¸ì…ì¥ - ParticipantConnected ëŒ€ê¸°')
    }

    // ìŒì„± ë…¹ìŒ ì‹œì‘ (ê³ ê° + ìƒë‹´ì› ë¯¹ìŠ¤)
    startRecording()

      // === ë§ˆì´í¬ í™œì„±í™” (í†µí™” í™”ë©´ ì§„ì… ì‹œ) ===
      ; (async () => {
        try {
          // setMicrophoneEnabled ëŒ€ì‹  ì§ì ‘ getUserMedia + publishTrack ì‚¬ìš©
          // (DataCloneError íšŒí”¼)
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true
            }
          })
          currentMicStream = stream

          const audioTrack = stream.getAudioTracks()[0]
          if (audioTrack) {
            await room.localParticipant.publishTrack(audioTrack, {
              name: 'microphone',
              source: Track.Source.Microphone
            })

            // ë§ˆì´í¬ê°€ í™œì„±í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ìŒì†Œê±° ìƒíƒœëŠ” false
            isMuted.value = false
            console.log('[CounselorCallView] ë§ˆì´í¬ í™œì„±í™” ì™„ë£Œ (ìŒì†Œê±° í•´ì œ ìƒíƒœ)')

            // ìƒë‹´ì› ë§ˆì´í¬ë¥¼ ë…¹ìŒ ë¯¹ìŠ¤ì— ì¶”ê°€
            addRecordingTrack(audioTrack)
          }
        } catch (err) {
          console.error('[CounselorCallView] ë§ˆì´í¬ í™œì„±í™” ì‹¤íŒ¨:', err)
          notificationStore.notifyError('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”')
          // ì‹¤íŒ¨ ì‹œ ìŒì†Œê±° ìƒíƒœë¡œ ì„¤ì •
          isMuted.value = true
        }
      })()

      // === ê³ ê° ì˜¤ë””ì˜¤ ë”œë ˆì´/ì°¨ë‹¨ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ===
      // 1) ì´ë¯¸ êµ¬ë…ëœ íŠ¸ë™ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ íŒŒì´í”„ë¼ì¸ ìƒì„±
      ; (async () => {
        await ensureAudioContext()

        for (const p of room.remoteParticipants.values()) {
          for (const pub of p.audioTrackPublications.values()) {
            if (pub.track) {
              await attachDelayedCustomerAudio(pub.track, p.identity)
              addRecordingTrack(pub.track.mediaStreamTrack)
            }
          }
        }

        // 2) ì´í›„ ìƒˆë¡œ êµ¬ë…ë˜ëŠ” íŠ¸ë™ì— ëŒ€í•´ì„œë„ ì ìš©
        room.on(RoomEvent.TrackSubscribed, async (track, publication, participant) => {
          if (track.kind === Track.Kind.Audio) {
            await attachDelayedCustomerAudio(track, participant.identity)
            addRecordingTrack(track.mediaStreamTrack)
          }
        })

        // 3) ê³ ê° STT ìˆ˜ì‹  â†’ í­ë ¥ì„± ê²€ì‚¬
        room.on(RoomEvent.DataReceived, async (payload, participant) => {
          const parsed = safeParsePayload(payload)
          if (!parsed || parsed.type !== 'stt') return

          // ë‹¤ìŒ STTê°€ ì™”ìœ¼ë©´, ì´ì „ ì°¨ë‹¨ì´ ìˆì—ˆë‹¤ë©´ í•´ì œ íƒ€ì´ë¨¸ë¥¼ ê±¸ì–´ë‘ 
          if (participant?.identity) scheduleUnblockOnNextStt(participant.identity)

          const text = String(parsed.text || '').trim()
          if (!text) return

          const { toxic, score } = await analyzeToxicity(text)
          if (toxic && participant?.identity) {
            blockCustomerAudioUntilNextStt(participant.identity)
          }

          addSttMessage({
            speaker: 'customer',
            text,
            maskedText: toxic ? maskText(text) : '',
            hasProfanity: toxic,
            confidence: 1 - score,
            participantId: participant?.identity || null
          })
        })

        // 4) ìƒë‹´ì› STT(Whisper) ì‹œì‘
        // await startCounselorWhisperVad()
      })()

    // ê³ ê°ì´ í†µí™”ë¥¼ ì¢…ë£Œí–ˆì„ ë•Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
    callStore.livekitRoom.on(RoomEvent.ParticipantDisconnected, async (participant) => {
      console.log('[CounselorCallView] ê³ ê°ì´ í†µí™”ë¥¼ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤:', participant.identity)

      // âš ï¸ ì¤‘ìš”: consultationIdë¥¼ ë¨¼ì € ì €ì¥
      const consultationId = callStore.currentConsultationId
      console.log('[CounselorCallView] ê³ ê° ì¢…ë£Œ - ì €ì¥ëœ consultationId:', consultationId)

      isCallActive.value = false

      // ìŒì„± ë…¹ìŒ ì¢…ë£Œ ë° íŒŒì¼ ë‹¤ìš´ë¡œë“œ
      await stopAndSaveRecording()

      // ë§ˆì´í¬ ì •ë¦¬ ë° LiveKit ì—°ê²° ì¢…ë£Œ
      await stopLocalMicrophone()
      if (callStore.livekitRoom) {
        try {
          await callStore.livekitRoom.disconnect()
        } catch (err) {
          console.error('[CounselorCallView] LiveKit ì—°ê²° ì¢…ë£Œ ì‹¤íŒ¨ (ê³ ê° ì¢…ë£Œ):', err)
        }
        callStore.setLivekitRoom(null)
      }

      // ëª¨ë‹¬ì„ ë¨¼ì € í‘œì‹œ (ë¡œë”© ìƒíƒœë¡œ)
      aiSummary.value = null // ë¡œë”© ìƒíƒœ
      showManualEndModal.value = true
      console.log('[CounselorCallView] ê³ ê° ì¢…ë£Œ ëª¨ë‹¬ í‘œì‹œ (AI ìš”ì•½ ë¡œë”© ì¤‘)')

      // AI ìš”ì•½ ìƒì„± (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰, ëª¨ë‹¬ì€ ì´ë¯¸ í‘œì‹œë¨)
      try {
        console.log('[CounselorCallView] ê³ ê° ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ì‹œì‘')
        const fullTranscript = sttMessages.value
          .map(msg => `${msg.speaker}: ${msg.text}`)
          .join('\n')

        // ë””ë²„ê¹… ë¡œê·¸
        console.log('[CounselorCallView] ğŸ” ê³ ê° ì¢…ë£Œ AI ìš”ì•½ ìƒì„± ì²´í¬:')
        console.log('  - consultationId:', consultationId)
        console.log('  - sttMessages ê°œìˆ˜:', sttMessages.value.length)
        console.log('  - fullTranscript ê¸¸ì´:', fullTranscript.trim().length)

        if (consultationId && fullTranscript.trim()) {
          const summary = await generateAISummary(consultationId, fullTranscript)
          aiSummary.value = summary
          console.log('[CounselorCallView] ê³ ê° ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ì™„ë£Œ:', summary)
        } else {
          console.warn('[CounselorCallView] ê³ ê° ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ìŠ¤í‚µ (consultationId ë˜ëŠ” transcript ì—†ìŒ)')
          aiSummary.value = {
            title: 'ìš”ì•½ ìƒì„± ì‹¤íŒ¨',
            subtitle: 'ìƒë‹´ ë‚´ìš©ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤',
            aiSummary: 'AI ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
          }
        }
      } catch (aiError) {
        console.error('[CounselorCallView] ê³ ê° ì¢…ë£Œ - AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨:', aiError)
        aiSummary.value = {
          title: 'ìš”ì•½ ìƒì„± ì‹¤íŒ¨',
          subtitle: 'AI ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤',
          aiSummary: 'ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
        }
      }

      // í†µí™” ì¢…ë£Œ ëª¨ë‹¬ í‘œì‹œ (ë©”ëª¨ ì €ì¥ìš©)
      showManualEndModal.value = true
      notificationStore.notifyInfo('ê³ ê°ì´ í†µí™”ë¥¼ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤')
    })
  } else {
    console.warn('[CounselorCallView] LiveKit ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹œë³´ë“œë¡œ ëŒì•„ê°€ì„¸ìš”.')
    // ì„ íƒì : ì—°ê²°ì´ ì—†ìœ¼ë©´ ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    // router.push('/dashboard')
  }
})

onBeforeUnmount(() => {
  console.log('[CounselorCallView] ì»´í¬ë„ŒíŠ¸ unmount ì‹œì‘')

  // ë§ˆì´í¬ stream ì •ë¦¬ (ë™ê¸°: ì¦‰ì‹œ ì‹¤í–‰í•˜ì—¬ ë¸Œë¼ìš°ì € ë§ˆì´í¬ ì ìœ  í•´ì œ)
  if (currentMicStream) {
    currentMicStream.getTracks().forEach(track => track.stop())
    currentMicStream = null
  }

  // ë§¤ì¹­ ë°ì´í„° ì •ë¦¬ (ëŒ€ì‹œë³´ë“œë¡œ ëŒì•„ê°ˆ ë•Œ)
  dashboardStore.clearMatchedData()
  console.log('[CounselorCallView] ë§¤ì¹­ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ')

  // Whisper/VAD ì •ë¦¬
  // stopCounselorWhisperVad()

  // ìŒì„± ë…¹ìŒ ì •ë¦¬
  cleanupRecorder()

  // ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì •ë¦¬
  try {
    for (const pipe of pipelines.values()) {
      pipe.fallbackEl?.pause()
      pipe.fallbackEl?.remove()
    }
    pipelines.clear()
    audioCtx?.close?.()
  } catch {
    // ignore
  } finally {
    audioCtx = null
  }
})
</script>